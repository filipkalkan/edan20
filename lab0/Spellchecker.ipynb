{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "inappropriate-river",
   "metadata": {},
   "source": [
    "Init functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "documented-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-buddy",
   "metadata": {},
   "source": [
    "Loading book \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "close-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = Counter(words(open('../corpus/Selma/gosta.txt').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mineral-species",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hej', 'jag', 'heter', 'frans']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words('Hej jag heter frans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "trained-laundry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00904367755572934"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P('jag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wired-transport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hej'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('heej')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "manufactured-british",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bege',\n",
       " 'ene',\n",
       " 'hade',\n",
       " 'hane',\n",
       " 'hare',\n",
       " 'heder',\n",
       " 'hej',\n",
       " 'hel',\n",
       " 'hela',\n",
       " 'helt',\n",
       " 'hem',\n",
       " 'hems',\n",
       " 'henne',\n",
       " 'herr',\n",
       " 'herre',\n",
       " 'hesa',\n",
       " 'het',\n",
       " 'heta',\n",
       " 'heter',\n",
       " 'hett',\n",
       " 'hette',\n",
       " 'huse',\n",
       " 'lede',\n",
       " 'leve',\n",
       " 'nere',\n",
       " 'vete'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates('heee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "academic-dispatch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'du', 'hej'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known(set(['hej', 'du', 'Frans']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "resident-animation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aej',\n",
       " 'ahej',\n",
       " 'bej',\n",
       " 'bhej',\n",
       " 'cej',\n",
       " 'chej',\n",
       " 'dej',\n",
       " 'dhej',\n",
       " 'eej',\n",
       " 'ehej',\n",
       " 'ehj',\n",
       " 'ej',\n",
       " 'fej',\n",
       " 'fhej',\n",
       " 'gej',\n",
       " 'ghej',\n",
       " 'haej',\n",
       " 'haj',\n",
       " 'hbej',\n",
       " 'hbj',\n",
       " 'hcej',\n",
       " 'hcj',\n",
       " 'hdej',\n",
       " 'hdj',\n",
       " 'he',\n",
       " 'hea',\n",
       " 'heaj',\n",
       " 'heb',\n",
       " 'hebj',\n",
       " 'hec',\n",
       " 'hecj',\n",
       " 'hed',\n",
       " 'hedj',\n",
       " 'hee',\n",
       " 'heej',\n",
       " 'hef',\n",
       " 'hefj',\n",
       " 'heg',\n",
       " 'hegj',\n",
       " 'heh',\n",
       " 'hehj',\n",
       " 'hei',\n",
       " 'heij',\n",
       " 'hej',\n",
       " 'heja',\n",
       " 'hejb',\n",
       " 'hejc',\n",
       " 'hejd',\n",
       " 'heje',\n",
       " 'hejf',\n",
       " 'hejg',\n",
       " 'hejh',\n",
       " 'heji',\n",
       " 'hejj',\n",
       " 'hejk',\n",
       " 'hejl',\n",
       " 'hejm',\n",
       " 'hejn',\n",
       " 'hejo',\n",
       " 'hejp',\n",
       " 'hejq',\n",
       " 'hejr',\n",
       " 'hejs',\n",
       " 'hejt',\n",
       " 'heju',\n",
       " 'hejv',\n",
       " 'hejw',\n",
       " 'hejx',\n",
       " 'hejy',\n",
       " 'hejz',\n",
       " 'hek',\n",
       " 'hekj',\n",
       " 'hel',\n",
       " 'helj',\n",
       " 'hem',\n",
       " 'hemj',\n",
       " 'hen',\n",
       " 'henj',\n",
       " 'heo',\n",
       " 'heoj',\n",
       " 'hep',\n",
       " 'hepj',\n",
       " 'heq',\n",
       " 'heqj',\n",
       " 'her',\n",
       " 'herj',\n",
       " 'hes',\n",
       " 'hesj',\n",
       " 'het',\n",
       " 'hetj',\n",
       " 'heu',\n",
       " 'heuj',\n",
       " 'hev',\n",
       " 'hevj',\n",
       " 'hew',\n",
       " 'hewj',\n",
       " 'hex',\n",
       " 'hexj',\n",
       " 'hey',\n",
       " 'heyj',\n",
       " 'hez',\n",
       " 'hezj',\n",
       " 'hfej',\n",
       " 'hfj',\n",
       " 'hgej',\n",
       " 'hgj',\n",
       " 'hhej',\n",
       " 'hhj',\n",
       " 'hiej',\n",
       " 'hij',\n",
       " 'hj',\n",
       " 'hje',\n",
       " 'hjej',\n",
       " 'hjj',\n",
       " 'hkej',\n",
       " 'hkj',\n",
       " 'hlej',\n",
       " 'hlj',\n",
       " 'hmej',\n",
       " 'hmj',\n",
       " 'hnej',\n",
       " 'hnj',\n",
       " 'hoej',\n",
       " 'hoj',\n",
       " 'hpej',\n",
       " 'hpj',\n",
       " 'hqej',\n",
       " 'hqj',\n",
       " 'hrej',\n",
       " 'hrj',\n",
       " 'hsej',\n",
       " 'hsj',\n",
       " 'htej',\n",
       " 'htj',\n",
       " 'huej',\n",
       " 'huj',\n",
       " 'hvej',\n",
       " 'hvj',\n",
       " 'hwej',\n",
       " 'hwj',\n",
       " 'hxej',\n",
       " 'hxj',\n",
       " 'hyej',\n",
       " 'hyj',\n",
       " 'hzej',\n",
       " 'hzj',\n",
       " 'iej',\n",
       " 'ihej',\n",
       " 'jej',\n",
       " 'jhej',\n",
       " 'kej',\n",
       " 'khej',\n",
       " 'lej',\n",
       " 'lhej',\n",
       " 'mej',\n",
       " 'mhej',\n",
       " 'nej',\n",
       " 'nhej',\n",
       " 'oej',\n",
       " 'ohej',\n",
       " 'pej',\n",
       " 'phej',\n",
       " 'qej',\n",
       " 'qhej',\n",
       " 'rej',\n",
       " 'rhej',\n",
       " 'sej',\n",
       " 'shej',\n",
       " 'tej',\n",
       " 'thej',\n",
       " 'uej',\n",
       " 'uhej',\n",
       " 'vej',\n",
       " 'vhej',\n",
       " 'wej',\n",
       " 'whej',\n",
       " 'xej',\n",
       " 'xhej',\n",
       " 'yej',\n",
       " 'yhej',\n",
       " 'zej',\n",
       " 'zhej'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edits1('hej')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "quiet-insulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object edits2.<locals>.<genexpr> at 0x7f516c9695f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edits2('hej')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-completion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
